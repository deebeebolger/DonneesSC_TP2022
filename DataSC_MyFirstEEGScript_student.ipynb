{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## FIRST STEPS IN EXPLORING EEG DATA\n",
    "\n",
    "Now that we have visualized and explore EEG data using Anywave, we will try to carry out similar work using Python and Python-MNE, a tool used by many researchers in EEG, MEG and fMRI.\n",
    "Make sure that the folders containing your data are in the same directory as your Jupyter notebooks and Python scripts. This will make it easier to load in data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib widget   # Magic command to allow us to interact with figures in Jupyter; only works in Jupyter.\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pyedflib\n",
    "import mne\n",
    "import ipympl\n",
    "import pandas as pd\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 6)},\n",
    "        font_scale=1.5)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "qt_api = os.environ.get('QT_API')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Load in an EDF dataset from the AuditoryOddball_TBI study folder.\n",
    "    We will read in the edf file using the pyedflib package.\n",
    "'''\n",
    "fname = './AuditoryOddball_TBI/sub-004/session1/sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg.edf'\n",
    "rawmed1 = pyedflib.EdfReader(fname)\n",
    "n = rawmed1.signals_in_file                        # Find the data in the file\n",
    "signal_labels = rawmed1.getSignalLabels()          # Find the channels names\n",
    "sigbufs = np.zeros((n, rawmed1.getNSamples()[0]))  # Initialize a sigbuf array to receive the data samples\n",
    "for i in np.arange(n):                             # For each channel add the data to the sigbuf array.\n",
    "    sigbufs[i, :] = rawmed1.readSignal(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TASK 1\n",
    "The sampling rate of the current dataset is 500Hz.\n",
    "This means that the signal is sampled 500 times in each second.\n",
    "Given this information, how can create a time vector that will tell us the time (in seconds) of every sample of data?\n",
    "There is some code included below to help you...\n",
    "\n",
    "First clue: if the sampling frequency is 500Hz, what is the time interval between each sample?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## -----------------------We know the sampling rate of the data, so can we construct the time vector?----------------------\n",
    "srate = 500\n",
    "datasize = sigbufs.shape      # This will give us the size of the sigbufs array:\n",
    "                              # datasize[0] = number of channels datasize[1]= number of samples\n",
    "X =\n",
    "i = range(0, X)     # Code to create a vector of length X\n",
    "time =              # Create a time vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now plot a single channel\n",
    "We will plot the Cz channel using the time vector that we just calculated above.\n",
    "We use the *index()* method to get the index of the Cz channel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "## Now we can plot the data of a single electrode over time.\n",
    "## We want to plot the Cz electrode...\n",
    "chanidx = signal_labels.index('Cz')      # Find the index of the Cz electrode.\n",
    "plt.plot(time,sigbufs[chanidx, :])       # Plot the Cz signal\n",
    "plt.xlabel('time (seconds)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot an individual channel over a defined time interval\n",
    "Here we will just plot the data of the Pz channel over the 60second to 70second time interval.\n",
    "This means that we need define a shorter time interval."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### But we may want to visualize individual channel data for a pre-defined time interval.\n",
    "\"\"\"Need to consctruct the new time vector\"\"\"\n",
    "lims_sec    = np.array([60, 70])               # We will define the limits of the time interval, from 60seconds to 70seconds\n",
    "lim1, lim2  = (lims_sec * srate).astype(int)   # Find the indices of the start and end of chosen time interval\n",
    "chan2plot   = 'Pz'                             # The index of the channel that you want to plot\n",
    "chanindx2   = signal_labels.index(chan2plot)\n",
    "RawIn_sel   = sigbufs[chanindx2, lim1:lim2]     # Extract the raw data of interest\n",
    "\n",
    "# Now plot the time interval of data.\n",
    "t = time[lim1:lim2]                             # We define a new time vector, t, as being between lim1 and lim2\n",
    "plt.plot(t,RawIn_sel)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot several channels over a defined time interval\n",
    "\n",
    "Here we will plot several channels over a predefined interval.\n",
    "We will plot these channels on the same plot, one above the other."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chans_sel    = ['C3', 'Cz', 'C4']                                     # Define the channels that you want to plot.\n",
    "chanidx3 = [signal_labels.index(item2) for item2 in chans_sel ]       # Find the indices of the channels that you want to plot.\n",
    "\n",
    "RawIn_sel2 = sigbufs[chanidx3, lim1:lim2]   # Extract the data from the\n",
    "yoffset    = np.array([.001, 0, .001])      # Define a y-offset to seperate the channels\n",
    "y          = RawIn_sel2.T + yoffset         # Extract the magnitude data for the selected channel\n",
    "                                            # RawIn_sel2.T finds the transpose of the data array - exchange between columns and rows\n",
    "pline = plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(pline, chans_sel)                 # We include a legend to show which signal corresponds to which channel.\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert the continuous data into an MNE Raw object.\n",
    "![](figures/mne.png)\n",
    "\n",
    "The Python-MNE package is very employed is the analysis of EEG and MEG data.\n",
    "MNE-Python provides many functions to visualize and explore EEG data.\n",
    "\n",
    "We create a what is called in MNE-Python a **Raw object** using the data that we loaded above.\n",
    "To create this Raw object we will need the following information:\n",
    "- the sampling rate (in Hertz) of the data\n",
    "- channel labels\n",
    "- channel types (EEG, EOG, MEG etc.)\n",
    "\n",
    "Of course, to create this raw object and to begin using the MNE functions, we need to have imported mne package.\n",
    "You will notice above that we do not include all the channels when creating the MNE Raw object, we exclude the external channels, EXG1 and EG2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ---------------- It is much easier to manipulate and visualize the data using the MNE Package -----------------------.\n",
    "\"\"\"\n",
    "    So we will create a simple MNE raw object called RawIn\n",
    "    Initialize an info structure with the following information:\n",
    "    - sampling rate (srate)\n",
    "    - channel labels (signal_labels)\n",
    "    - channel types (eeg) - we need to create this list\n",
    "\"\"\"\n",
    "# Create the channel type list. All channels are type EEG.\n",
    "\n",
    "siglabs   = signal_labels\n",
    "chantypes = ['eeg'] * len(siglabs)\n",
    "sigIn     = sigbufs[0:len(siglabs), :]\n",
    "info = mne.create_info(ch_names=siglabs, ch_types=chantypes, sfreq=srate)\n",
    "RawIn = mne.io.RawArray(sigIn, info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop unwanted channels and mark channels\n",
    "We will not use the status channel here, so we will drop it.\n",
    "We will define the type of the 'VEOG' channel as an ocular channel (eog).\n",
    "This means that we can distinguish it from the scalp electrodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RawIn.drop_channels('Status')\n",
    "RawIn.set_channel_types({'VEOG': 'eog'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The **Raw object**\n",
    "If you take a look inside the **RawIn** object, you will see that it has different *attributes* such as:\n",
    "- n_times : number of time samples\n",
    "- ch_names : the names of the channels\n",
    "- times : the time vector\n",
    "- an *info* dictionnary with acquisition details such as sampling rate, labels of channels marked as *bad* etc.\n",
    "\n",
    "Below we will access this information and print it to screen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = RawIn.times\n",
    "Allchans =  RawIn.info['ch_names']\n",
    "badchans =  RawIn.info['bads']\n",
    "sampfreq =  RawIn.info['sfreq']\n",
    "\n",
    "print('The sampling frequency is: []', sampfreq)\n",
    "print('The first 5 channel names are: {}'.format(', '.join(Allchans[:5])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting All EEG Channels\n",
    "\n",
    "Now we will plot the raw signals of all channels stacked on above the other over time.\n",
    "In the following two cells, we apply two different ways of plotting the EEG signals.\n",
    "\n",
    "Note that **remove_dc** is set to **True** or \"On\". What do you think this means?\n",
    "\n",
    "What might we expect if we set **remove_dc** to **False**?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Visualise all electrode activity #####\n",
    "\n",
    "%matplotlib widget\n",
    "mne.viz.plot_raw(RawIn, scalings='auto', remove_dc=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## We can also plot the data in the RawIn object by using RawIn's '\"plot\" method\n",
    "\n",
    "RawIn.plot(duration= 20, start = 60, scalings='auto', remove_dc=True, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### WHAT IF WE WANT TO PLOT ONLY A SPECIFIC TIME INTERVAL?\n",
    "\n",
    "In the cell below, you have to plot a single channel, Cz, over the for the 60-70second time window.\n",
    "You first need to construct the time vector.\n",
    "\n",
    "\n",
    "Some help:\n",
    "- You will need to know the sampling frequency (Hz or samples per second) of the data.\n",
    "- The time vector and data vector, corresponding to data from Cz electrode, need to have the same length.\n",
    "- Need to find the index of Cz electrode."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### But we may want to visualize individual channel data for a pre-defined time interval.\n",
    "\"\"\"Need to consctruct the new time vector\"\"\"\n",
    "lims_sec    = np.array([60, 70])\n",
    "lim1, lim2  = (lims_sec * sampfreq).astype(int)   # Find the indices of the start and end of chosen time interval\n",
    "chan_idx    = Allchans.index('Cz')                # The index of the channel that you want to plot\n",
    "RawIn_sel   = RawIn[chan_idx, lim1:lim2]          # Extract the raw data of interest\n",
    "\n",
    "%matplotlib inline\n",
    "t = RawIn_sel[1]                             # Extract the time vector\n",
    "y = RawIn_sel[0].T                           # Extract the magnitude data for the selected channel\n",
    "plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### USE OF RAW METHODS TO GET THE INDICES OF TIME POINTS (IN SECONDS)\n",
    "The Raw method **time_as_index()** can be used to convert a time, in seconds, into an integer index.\n",
    "The times can be presented as a list or an array of times and, in that case, will return an array of indices.\n",
    "\n",
    "In addition, we can also index our Raw object, RawIn, using the channel names rather than the indices.\n",
    "Here we select 3 central channels to plot in a stacked plot.\n",
    "So as to differentiate the signals of each channel, we define an offset for the y axis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Use of the Raw method \"time_as_index\" to find the index\n",
    "Lims = RawIn.time_as_index(lims_sec)\n",
    "list_idx = Lims.tolist()\n",
    "print('The start and end indices of the 60 to 70sec time interval is : ', list_idx)\n",
    "\n",
    "chan_sel    = ['C3', 'Cz', 'C4']                                     # The index of the channel that you want to plot\n",
    "RawIn_sel2 = RawIn[chan_sel, Lims[0]:Lims[1]]\n",
    "yoffset = np.array([.001, 0, .001])\n",
    "t = RawIn_sel2[1]                             # Extract the time vector\n",
    "y = RawIn_sel2[0].T + yoffset                         # Extract the magnitude data for the selected channel\n",
    "pline = plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(pline, chan_sel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ---------------------------------- PLOT TOPOGRAPHIES FOR DEFINED TIME INTERVAL -----------------------------------\n",
    "\n",
    "In addition to looking at the signal as a function of time.\n",
    "We can look at the spatial distribution of activity across the head (topography) for a given time interval.\n",
    "We could do this to highlight activity as a specific time or verify if certain activity corresponds to an artifact.\n",
    "The plot a single topography, we need to define a vector of the mean activity over a defined time interval.\n",
    "\n",
    "- Try to find a time interval containing eye-blinks or ECG or alpha oscillation.\n",
    "- Note the time interval or intervals.\n",
    "- Plot the topography of the activity over this time interval.\n",
    "\n",
    "The function to plot topography is given below.\n",
    "You can use the EEG artifact, characteristics CheatSheet to help you detect these artifacts.\n",
    "Note: Before we can visualise the topography, we need to define the electrode layout or **montage** that corresponds\n",
    "to the current data.\n",
    "Here we use the standard 10-20 montage.\n",
    "\n",
    "<img src=\"figures/10-20_1.jpg\" width=520 height=550 /><br />"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "    Add the montage information to the current raw object, RawIn.\n",
    "    This is required if you want to plot the topography maps.\n",
    "'''\n",
    "montage = mne.channels.make_standard_montage('standard_1020')               # Assigning the standard 10-20 montage\n",
    "mne.viz.plot_montage(mne.channels.make_standard_montage('standard_1020'))   # Visualize the montage\n",
    "RawIn.set_montage(montage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### THE DC OFFSET\n",
    "\n",
    "We will start by trying to remove the DC offset, by subtracting the mean activity from the activity of one channel.\n",
    "Then we will plot the result.\n",
    "So...\n",
    "- Let's calculate the mean of a few channels.\n",
    "- What do you notice about the means? How do we know that there is a DC offset?\n",
    "\n",
    "Note also the use of the *copy()** method. We use this to make a copy of the original **RawIn** object.\n",
    "When we apply a method such as, *.pick_channels*, to a raw object, we change that object. Therefore, the copy() method is very useful."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## To test the effect of the DC offset, we will find the mean of a few electrodes.\n",
    "\"\"\"\n",
    "    Find the mean of the data from several channels.\n",
    "    What can we say about the means?\n",
    "\"\"\"\n",
    "RawIn_temp = RawIn.copy()                     # Create a copy of the RawIn object and name it RawIn_temp\n",
    "RawIn_temp.pick_channels(['F3', 'Fz', 'F4'])  # We are going to compute of a subset of channels.\n",
    "dataIn    = RawIn_temp.get_data()             # Extract the data from the RawIn object.\n",
    "data_mean = np.mean(dataIn, 1)                # We want to find the mean over the time samples, so the 2nd dimension.\n",
    "Dmean = data_mean.tolist()                    # Converting the array to a list.\n",
    "print('The mean for each  electrode: {} '.format(Dmean))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing the DC Offset\n",
    "\n",
    "So, if we think we need to remove the DC offset, we can do the following:\n",
    "- Subtract the mean of each signal from each time sample of each channel.\n",
    "- Carry out high-pass filtering to remove the 0Hz\n",
    "- Carry out **detrending**\n",
    "\n",
    "In the following, you can compare the effect of subtracting the mean and high-pass filtering.\n",
    "We can carry out this test on the **RawIn_sel2** data, that consists of 6 channels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Subtract the mean\n",
    "# We already know the means of the 6 channels, they are stored in the Dmean list and the data_mean array.\n",
    "# The channel-data of the RawIn_temp object is \"dataIn\"\n",
    "chan_demean1 = dataIn[0,] - Dmean[0]\n",
    "chan_demean2 = dataIn[1,] - Dmean[1]\n",
    "chan_demean3 = dataIn[2,] - Dmean[2]\n",
    "\n",
    "%matplotlib inline\n",
    "## Plot the original and demeaned channels\n",
    "ax1 = plt.subplot(231)\n",
    "ax1.margins(0.5)\n",
    "ax1.plot(T, dataIn[0,])\n",
    "\n",
    "ax2 = plt.subplot(232)\n",
    "ax2.margins(0.5)\n",
    "ax2.plot(T,dataIn[1,])\n",
    "\n",
    "ax3 = plt.subplot(233)\n",
    "ax3.margins(0.5)\n",
    "ax3.plot(T,dataIn[2,])\n",
    "\n",
    "ax4 = plt.subplot(234)\n",
    "ax4.margins(0.5)\n",
    "ax4.plot(T, chan_demean1)\n",
    "\n",
    "ax5 = plt.subplot(235)\n",
    "ax5.margins(0.5)\n",
    "ax5.plot(T,chan_demean2)\n",
    "\n",
    "ax6 = plt.subplot(236)\n",
    "ax6.margins(0.5)\n",
    "ax6.plot(T,chan_demean3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FILTERING THE EEG SIGNAL\n",
    "\n",
    "In EEG, we generally filter to remove high frequency artifacts and low frequency drifts.\n",
    "We can filter our time-domain data, our continuous EEG.\n",
    "We can also filter our spatial-domain data using spatial filters.\n",
    "\n",
    "We begin by filtering our time-domain data:\n",
    "- we apply a high-pass filter to remove low frequency drifts\n",
    "- we apply a low-pass filter to remove high frequency artifacts.\n",
    "Here we are going to apply a *high-pass filter* only to try to remove the DC offset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Filter the EEG Signal.\n",
    "# band-pass filtering in the range 0.1 Hz - 40 Hz\n",
    "RawIntemp_filt = RawIn_temp.copy().filter(0.1, None, fir_design='firwin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2:\n",
    "Plot the unfiltered, the demeaned and the filtered data of a single electrode to compare the effects subtracting the mean and high-pass filtering.\n",
    "Write your code in the cell below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## THE SAMPLING FREQUENCY (Hz) AND DOWNSAMPLING\n",
    "\n",
    "Represents the number of times per second that the acquisition system samples the continuous EEG.\n",
    "So, given sampling frequency (or sampling rate) of 1024Hz, this means that the system samples the signal every ______ seconds?\n",
    "\n",
    "The sampling rate has an effect on the analyses that we can carry out on the EEG.\n",
    "For example, if we are interested interested in studying EEG activity around 80Hz, sampling frequency needs to be **at least** twice this frequency of interest - this is the **Nyquist Rule**.\n",
    "\n",
    "However, having a high sampling frequency also implies having a greater volume of data. This can mean longer computing times when we are analysing our data.\n",
    "Generally, in EEG analysis, we are interested in activity in the 0.1Hz to 80Hz frequency band. This means that we do not necessarily need to have a sampling frequency as high as 1024Hz; a sampling frequency of 512Hz or 250Hz will be sufficient to capture the characteristics of the EEG of interest.\n",
    "\n",
    "To reduce the rate at which our EEG is sampled, we can **resample** or **downsample** our data.\n",
    "- How does resampling change the EEG signal?\n",
    "- What other variable is automatically changed when we resample the EEG data?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rsamp = srate/2                                    # Downsample to half of the original sampling frequency.\n",
    "RawIn_rs = RawIn.copy().resample(sfreq=rsamp)      # Create a copy of RawIn and apply downsampling to this copy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FILTERING THE EEG SIGNAL\n",
    "\n",
    "In EEG, we generally filter to remove high frequency artifacts and low frequency drifts.\n",
    "We can filter our time-domain data, our continuous EEG.\n",
    "We can also filter our spatial-domain data using spatial filters.\n",
    "\n",
    "We begin by filtering our time-domain data:\n",
    "- we apply a high-pass filter to remove low frequency drifts\n",
    "- we apply a low-pass filter to remove high frequency artifacts."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3:\n",
    "\n",
    "# Plot the filtered data to compare with the non-filtered data (**RawIn_rs** object) for different channels.\n",
    "\n",
    "This can be carried out in the cell below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "  Task 3 code goes in this cell.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "    Here we will plot the EEG signals for all the filtered data using the viz method of mne.\n",
    "'''\n",
    "\n",
    "%matplotlib widget\n",
    "mne.viz.plot_raw(RawIn_filt, scalings='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the Frequency Spectrum of EEG Signals\n",
    "\n",
    "When trying to detect noisy electrodes it is helpful to look at the frequency spectrum of the electrodes.\n",
    "The presence of low frequency or high frequency activity with a lot of energy can indicate a noisy electrode.\n",
    "Below we will plot the **Power Spectral Density (PSD)** for frequencies between 0.5Hz and 40Hz.\n",
    "The power spectral density will be plotted in dB.\n",
    "You can try plotting it again but setting the dB to **False**, can you see a difference?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "mne.viz.plot_raw_psd(RawIn_filt, fmin=0.5, fmax=40, dB=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mark the Noisy Channels as \"Bad\"\n",
    "\n",
    "Because activity that corresponds to noise is very often of higher amplitude than the EEG activity that interests us.\n",
    "We can detect bad electrodes by considering:\n",
    "- the time course of the signals.\n",
    "- the frequency spectrum of the signals.\n",
    "It is important to detect these souces of noise so that we can exclude them from our analysis.\n",
    "Here we will mark the noisy channels as **bad** so that we can exclude them from our analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 4:\n",
    "# Can you find any noisy electrodes that we may need to exclude from our data?\n",
    "# Plot the time course and the frequency spectra of these electrodes to justify your choice.\n",
    "You can do this task in the cell below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "   The code for Task 4 can go here.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "        We mark a channel as \"bad\" by adding it to the \"bads\" attribute of \"info\".\n",
    "'''\n",
    "ChanBad = ['Fp1']\n",
    "RawIn_filt.info['bads'] = ChanBad\n",
    "\n",
    "# Plot the PSD again but without the channel marked as \"bad\".\n",
    "mne.viz.plot_raw_psd(RawIn_filt, fmin=0.5, fmax=40, dB=True, exclude='bads')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Re-referencing the EEG:\n",
    "\n",
    "The potential measured in microVolts is measured in relation to the potential at another point, called the reference.\n",
    "\n",
    "This means that the activity at each channel is interpreted relative to the potential at a reference.\n",
    "- the reference can be the mean activity of all electrodes.\n",
    "- the average of the two mastoids (generally these reference channels are marked as Ref1, Ref2 or EXG1, EXG2)\n",
    "The current dataset does not have the external (EXG) channels, so we will apply an average reference.\n",
    "\n",
    "However, we cannot include the bad channels or the VEOG when applying the reference.\n",
    "We use the *pick_types()* method to exclude these channels when applying the average reference.\n",
    "\n",
    "<a href=\"https://predictablynoisy.com/mne-python/generated/mne.set_eeg_reference.html\"> Link to MNE page on **mne.set_eeg.reference()**</a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "    Note that we are excluding the eog channel and the bad channels from the average reference calculation.\n",
    "'''\n",
    "RawIn_ref = RawIn_filt.copy().pick_types(eeg=True, exclude= ['bads','eog']).set_eeg_reference()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visual Inspection and Annotation of Data\n",
    "\n",
    "Visually inspect the raw data, **RawIn_ref** by calling **RawIn_ref.plot()\n",
    "\n",
    "Bad channels are color coded gray. By clicking the lines or channel names on the left, you can mark or unmark a bad channel interactively. You can use +/- keys to adjust the scale (also = works for magnifying the data). Note that the initial scaling factors can be set with parameter scalings. If you don’t know the scaling factor for channels, you can automatically set them by passing scalings=’auto’. With pageup/pagedown and home/end keys you can adjust the amount of data viewed at once.\n",
    "\n",
    "You can enter annotation mode by pressing a key. In annotation mode you can mark segments of data (and modify existing annotations) with the left mouse button. You can use the description of any existing annotation or create a new description by typing when the annotation dialog is active. Notice that the description starting with the keyword 'bad' means that the segment will be discarded when epoching the data. Existing annotations can be deleted with the right mouse button. Annotation mode is exited by pressing a again or closing the annotation window.\n",
    "\n",
    "This functionality can bug a bit!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 5:\n",
    "Manually annotate the continuous by marking examples of the following, if you find them:\n",
    "- Eye-blinks\n",
    "- Electrode jumps\n",
    "- Cardiac artifact (ECG)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### HERE WE WILL MANUALLY ANNOTATE THE CONTINUOUS DATA TO MARK EYE-BLINKS OR BIG ELECTRODE JUMPS\n",
    "fig = RawIn_ref.plot(block=True)              # Open the interactive raw.plot window. This should open a separate window.\n",
    "fig.canvas.key_press_event('a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automatic Detection of Eye-Blinks\n",
    "In MNE there is a function that automatically identifies eye-blinks.\n",
    "It allows you to segment the data around the eye-blinks identified and then plot the spatial distribution of the activity corresponding to eye-blinks.\n",
    "However, to identify the eye-blinks you need to define a channel on which eye-blinks clearly appear.\n",
    "In the code we have set this channel to be **AF8** but it may not be the best choice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eogev_elec = 'AF8'                                #Put the label of your selected electrode here...try different electrodes.\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(RawIn_ref, ch_name=eogev_elec, reject_by_annotation=False)\n",
    "eog_epochs.apply_baseline(baseline=(None, -0.2))  # We go from the start of the interval to the -200ms before 0ms\n",
    "eog_epochs.average().plot_joint()\n",
    "eog_epochs.average().plot_topomap()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automatic Detection of ECG (Cardiac activity)\n",
    "In MNE there is a function that automatically identifies cardiac activity (ECG).\n",
    "It allows you to segment the data around the eye-blinks identified and then plot the spatial distribution of the activity corresponding to ECG.\n",
    "However, to identify the cardiac artifacts you need to define a channel on which they clearly appear.\n",
    "Can you identify any channel that clearly displays cardiac artifact?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ecg_elec = '';\n",
    "ecg_epochs = mne.preprocessing.create_ecg_epochs(RawIn_ref, ch_name=ecg_elec, reject_by_annotation=False)\n",
    "ecg_epochs.apply_baseline(baseline=(, ))              # Can you suggest a baseline interval for ECG??\n",
    "ecg_epochs.average().plot_joint()\n",
    "ecg_epochs.average().plot_topomap()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot topomaps of Continuous Data\n",
    "Generally, when we plot topomaps of continuous data, we plot the topomaps over a defined interval or, more interesting, we plot the spatial distribution corresponding to different frequency activity in the EEG spectrum.\n",
    "In the example below, we look at the spatial distribution of activity at 10Hz, this corresponds to alpha frequency band.\n",
    "In this example, we calculate the frequency content of the EEG over time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "### In continuous data, it is more interesting to look at frequency band activity.\n",
    "spectra, freqs = mne.time_frequency.psd_welch(RawIn_filt, fmin=1, fmax=40, tmin=0, tmax=250,\n",
    "                                              n_overlap=125, n_fft=250)\n",
    "print(freqs)       # Print the frequencies to screen.\n",
    "\n",
    "# Plot the spectra as a function of frequency.\n",
    "plt.plot(freqs, spectra.T)\n",
    "plt.ylabel(r'PSD ($\\mu$V^2)')\n",
    "\n",
    "## To start with, lets plot the topography of alpha activity (10Hz) across our continuous data.\n",
    "layout = mne.find_layout(RawIn_filt.info, ch_type='eeg', exclude='bads')\n",
    "mne.viz.plot_topomap(spectra[:, 9],layout.pos , cmap=cm.viridis, contours=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmenting the Continuous Data to look at **Evoked** Activity\n",
    "\n",
    "We have been looking at the continuous data.\n",
    "But, in EEG, we often like to look at the EEG in relation to a stimulus presented during the experiment.\n",
    "We are interested in the activity **evoked** by the stimuli.\n",
    "\n",
    "To study this **evoked** activity, we segment our data around the stimuli used in our study.\n",
    "This means that the chop the data into segments, called **epochs**, by defining a time interval before the stimulus (**baseline**) and a time interval after the stimulus (**post-stimulus interval**).\n",
    "\n",
    "In the example below we will load the *.csv file in which the timing of the stimuli are defined.\n",
    "Then we can this **event** data to our Raw object and the segment the continuous data.\n",
    "\n",
    "***\n",
    "In the data used here, the stimuli are the following:\n",
    "- A Standard Tone\n",
    "- A Novel Tone\n",
    "- A Target Tone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\n",
    "    './AuditoryOddball_TBI/sub-002/session1/sub-002_ses-01_task-ThreeStimAuditoryOddball_events.csv', sep=';', header=None)\n",
    "annotations = mne.Annotations(event_data[0], event_data[1], event_data[2])\n",
    "RawIn_filt.set_annotations(annotations)\n",
    "events, events_id = mne.events_from_annotations(RawIn_filt)\n",
    "print(events_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "   Segmenting the Continuous Data, we will first segment around all the events.\n",
    "'''\n",
    "\n",
    "tmin, tmax = [ -0.1,1 ]\n",
    "reject_criteria = dict(eeg=40e-6)   # Criterion for epoch rejection\n",
    "event_dict = {'Novel Tone': 1, 'Standard Tone': 2, 'Target Tone': 3}\n",
    "# Call of function to segment the data into epochs.\n",
    "epoch_data = mne.Epochs(RawIn_filt, events, event_id=event_dict, tmin=tmin, tmax=tmax, reject=None, reject_by_annotation=False,\n",
    "                        baseline=(tmin, 0), preload=True,\n",
    "                        detrend=None, verbose=True)\n",
    "\n",
    "fig = mne.viz.plot_events(events, event_id=event_dict, sfreq=RawIn_filt.info['sfreq'],\n",
    "                          first_samp=RawIn_filt.first_samp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Epoched Data\n",
    "- Here we plot the epoched data of the *Novel Tone* condition only.\n",
    "- The frequency spectrum of the *Novel Tone* activity.\n",
    "- An ERP-image and mean activity for the *Novel Tone* condition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "epoch_data['Novel Tone'].plot(events=events, event_id=event_dict, butterfly=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_data['Novel Tone'].plot_psd(picks='eeg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_data['Novel Tone'].plot_image(picks='eeg', combine='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the Evoked Activity for each condition\n",
    "We calculate the **evoked** activity for each condition (or stimulus) by averaging over all the epochs corresponding to that stimulus.\n",
    "Now we can compare the EEG activity for each experimental condition.\n",
    "\n",
    "**Note:** The results here are not very informative as we are looking at the evoked activity of a single subject.\n",
    "Normally, we calculate the average activity over several participants."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs_novel = epoch_data['Novel Tone']\n",
    "epochs_standard = epoch_data['Standard Tone']\n",
    "\n",
    "# Now we will average over the novel and standard trials. This will give us our evoked activity.\n",
    "evoked_novel = epochs_novel.average()\n",
    "evoked_standard = epochs_standard.average()\n",
    "\n",
    "mne.viz.plot_compare_evokeds(dict(novel=evoked_novel, standard=evoked_standard),\n",
    "                             legend='upper left', show_sensors='upper right')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}